{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {}
   },
   "source": [
    "# Exercise 3 - SAKI\n",
    "\n",
    "The purpose of this exercise is to develop an algorithm that optimizes the route that a robot takes for pick-up and storage of items in a warehouse.\n",
    "\n",
    "There are the following constraints : \n",
    "\n",
    "* Size of warehouse is {1..3} x {1..3}\n",
    "* There is separate start/stop position outside the 3x3 storage space\n",
    "* The first position the robot can move into is always (1, 1)\n",
    "* Robots can move to adjacent fields (but not diagonally)\n",
    "* There are three types of items, identified by color (white, blue, red)\n",
    "\n",
    "\n",
    "Here are the main lines of our work plan\n",
    "* I. Introduction \n",
    "\n",
    "* II. Data Analysis / Data Extraction\n",
    "\n",
    "* III. Markov Decision Process\n",
    "\n",
    "* IV. Testing\n",
    "\n",
    "* V. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Introduction\n",
    "\n",
    "Reinforcement learning (RL) is learning what to do, how to map situations to actions, so as to maximize\n",
    "a numerical reward signal. The learner is not told which actions to take, but instead must discover\n",
    "which actions yield the most reward by trying them.\n",
    "\n",
    "In short, we can say that reinforcement learning is learning by trying.\n",
    "\n",
    "In RL there is no supervisor, only a reward signal or a real number that tells the agent how good or bad was his action. \n",
    "Feedback from the environment might be delayed over several time steps, it’s not necessarily instantaneous \n",
    "e.g. for the task of reaching a goal in a grid-world, the feedback might be at the end when the agent reaches the goal. \n",
    "The agent might spend some time exploring and wandering in the environment until it finally reaches the goal after a while to realize what were the good and bad actions it has taken.\n",
    "\n",
    "In machine learning or supervised learning, we have a dataset that describes the environment to the algorithm and the right answers or actions to do when faced with a specific situation, and the algorithm tries to generalize from that data to new situations.\n",
    "\n",
    "In RL the agent influences the environment through its actions which in turn affect the subsequent data it receives from the environment, it’s an active learning process.\n",
    "\n",
    "In the problem, an agent is supposed to decide the best action to select based on his current state. When this step is repeated, the problem is known as a __Markov Decision Process__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# We start by importing all the librairies necessary for ourn work.\n",
    "import csv\n",
    "from itertools import product\n",
    "import mdptoolbox\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Data Analysis / Data Extraction\n",
    "\n",
    "Before defining the different parameters of the Markov Decision Process, we will start by importing our different data for analysis. \n",
    "\n",
    "We have 2 files at our disposal representing the training set and the testing set. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "    action  color\n",
      "0    store    red\n",
      "1    store    red\n",
      "2    store    red\n",
      "3    store  white\n",
      "4  restore    red\n",
      "----- -----\n",
      "Testing Set\n",
      "    action  color\n",
      "0    store    red\n",
      "1    store  white\n",
      "2  restore  white\n",
      "3    store    red\n",
      "4    store   blue\n"
     ]
    }
   ],
   "source": [
    "# import file training and testing file into a variable\n",
    "\n",
    "training_data_set = pd.read_csv(\"data/SAKI Exercise 3 warehousetraining2x2.txt\", delimiter='\\t', names=[\"action\", \"color\"])\n",
    "testing_data_set = pd.read_csv(\"data/SAKI Exercise 3 warehouseorder2x2.txt\", delimiter='\\t', names=[\"action\", \"color\"])\n",
    "\n",
    "print('Training Set')\n",
    "print(training_data_set.head())\n",
    "print('----- -----')\n",
    "print('Testing Set')\n",
    "print(testing_data_set.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have imported our training and test data. \n",
    "\n",
    "We will calculate the distribution of the different items and actions in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>color</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>restore</td>\n",
       "      <td>blue</td>\n",
       "      <td>0.121683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>restore</td>\n",
       "      <td>red</td>\n",
       "      <td>0.252415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>restore</td>\n",
       "      <td>white</td>\n",
       "      <td>0.125841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>store</td>\n",
       "      <td>blue</td>\n",
       "      <td>0.121683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>store</td>\n",
       "      <td>red</td>\n",
       "      <td>0.252415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>store</td>\n",
       "      <td>white</td>\n",
       "      <td>0.125963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    action  color     count\n",
       "0  restore   blue  0.121683\n",
       "1  restore    red  0.252415\n",
       "2  restore  white  0.125841\n",
       "3    store   blue  0.121683\n",
       "4    store    red  0.252415\n",
       "5    store  white  0.125963"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution_training = training_data_set.copy()\n",
    "distribution_training = distribution_training.groupby(['action', 'color']).size().reset_index(name='count')\n",
    "distribution_training['count'] = distribution_training['count'].div(len(training_data_set))\n",
    "\n",
    "distribution_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Markov Decision Process\n",
    "\n",
    "The Markov decision process, better known as MDP, is an approach in reinforcement learning to take decisions in a gridworld environment. A gridworld environment consists of states in the form of grids.\n",
    "\n",
    "Markov decision processes formally describe an environment for reinforcement learning, where the environment is fully observable ie the current state completely characterises the process\n",
    "\n",
    "Markov property : \"The future is independent of the past given the present\"\n",
    "\n",
    "Thus, any reinforcement learning task composed of a set of states, actions, and rewards that follows the Markov property would be considered an MDP.\n",
    "\n",
    "The solution to an MDP is called a policy and the objective is to find the optimal policy for that MDP task.\n",
    "\n",
    "A Markov Decision Process (MDP) model contains:\n",
    "\n",
    "* A set of possible world states S.\n",
    "* A set of Models.\n",
    "* A set of possible actions A.\n",
    "* A real valued reward function R(s,a).\n",
    "* A policy the solution of Markov Decision Process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Actions\n",
    "\n",
    "A is a set of all possible action. A(s) defines the set of actions that can be taken being in state S.\n",
    "\n",
    "Our robot can either retrieve or deposit objects in the warehouse. However, it should be noted that we have 3 different types of items, which will make us take different actions depending on the item chosen.\n",
    "\n",
    "in short, our robot will be able to perform the different actions: \n",
    "\n",
    "* pick up or store red item --> pick_up_red, store_red\n",
    "* pick up or store blue item --> pick_up_blue, store_blue\n",
    "* pick up or store white item --> pick_up_white, store_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_actions = ['pick_up_red', 'pick_up_blue', 'pick_up_white', 'store_red', 'store_blue', 'store_white']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "## 2. States\n",
    "\n",
    "A State is a set of tokens that represent every state that the agent can be in.\n",
    "\n",
    "Given our environment (warehouse 2*2) we can have different states depending on the items that would be present in the warehouse. In short, to obtain our states we must think of all the possible combinations in which our environment could be found. \n",
    "\n",
    "For example: at the beginning our warehouse is empty, or the warehouse already contains a red item or the warehouse already contains 2 blue items...\n",
    "\n",
    "we can therefore see that each of the above scenarios constitutes different states of our environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('empty', 'empty', 'empty', 'empty', 'pick_up_red'), ('empty', 'empty', 'empty', 'empty', 'pick_up_blue'), ('empty', 'empty', 'empty', 'empty', 'pick_up_white'), ('empty', 'empty', 'empty', 'empty', 'store_red'), ('empty', 'empty', 'empty', 'empty', 'store_blue'), ('empty', 'empty', 'empty', 'empty', 'store_white'), ('empty', 'empty', 'empty', 'red', 'pick_up_red'), ('empty', 'empty', 'empty', 'red', 'pick_up_blue'), ('empty', 'empty', 'empty', 'red', 'pick_up_white'), ('empty', 'empty', 'empty', 'red', 'store_red')]\n"
     ]
    }
   ],
   "source": [
    "stored_item = ['empty', 'red', 'blue', 'white']\n",
    "all_states = list(product(stored_item, stored_item, stored_item, stored_item, all_actions))\n",
    "\n",
    "assert len(all_states) == 1536\n",
    "print(all_states[:10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model \n",
    "\n",
    "A model (sometimes called Transition Model) is a transition function P, which predicts the next state or the dynamics of the environnement. \n",
    "\n",
    "It tell us the probability distribution over next possible successor states, given the current state and the action taken by the agent.\n",
    "\n",
    "Pa(s, s') is the transition probability matrix with the probabilities to lead from state s into another state s' within the action a\n",
    "\n",
    "For the choice of probabilities we will base ourselves on the analysis of the training data that we carried out a little earlier. We were able to see a fairly even distribution for red and blue items and a larger distribution for red items.\n",
    "Another solution would also be to start with an equiprobability for each item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a 2*2 warehouse or a total of 4 slots, we can therefore number them from 0 to 3 in order to identify each slot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "slot_positions = [0, 1, 2, 3]\n",
    "travel_costs=[1,2,3,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we will now create all our probability transition matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]], dtype=float16)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transition_probability_matrix_correction(tpm):\n",
    "    for index, row_vector in enumerate(tpm):\n",
    "        sum = np.sum(row_vector)\n",
    "        if sum == 0:\n",
    "            tpm[index, index] = 1\n",
    "            continue\n",
    "    tpm = tpm / tpm.sum(axis=1)[:, None]\n",
    "    return tpm\n",
    "\n",
    "\n",
    "def check_pick_up_action(agent_position, current_state, next_state):\n",
    "    item_color_to_pick_up = current_state[len(slot_positions)]\n",
    "    \n",
    "    # check if the wharehouse have already this item\n",
    "    if not item_color_to_pick_up in current_state[:4:]:\n",
    "        return False\n",
    "    \n",
    "    if current_state[agent_position] == item_color_to_pick_up and next_state[agent_position] == 'empty':\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "    \n",
    "\n",
    "def check_store_action(agent_position, current_state, next_state):\n",
    "    if not 'empty' in current_state:\n",
    "        return False\n",
    "    \n",
    "    item_color_to_store = current_state[4].split(sep='_')[-1]\n",
    "    \n",
    "    if current_state[agent_position] == 'empty' and next_state[agent_position] == item_color_to_store:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "def check_transition(agent_position, current_state, next_state):\n",
    "    current_action = current_state[4]\n",
    "    if current_action == 'pick_up_red' or current_action == 'pick_up_blue' or current_action == 'pick_up_white':\n",
    "        return check_pick_up_action(agent_position, current_state, next_state)\n",
    "    else:\n",
    "        return check_store_action(agent_position, current_state, next_state)\n",
    "\n",
    "    \n",
    "all_tpm = []\n",
    "for agent_position in slot_positions:\n",
    "    tpm = np.zeros((len(all_states), len(all_states)), dtype=np.float16)\n",
    "    for i, current_state in enumerate(all_states, start=0):\n",
    "        for j, next_state in enumerate(all_states, start=0):\n",
    "            if check_transition(agent_position, current_state, next_state):\n",
    "                next_action = next_state[4]\n",
    "                if next_action == 'store_red':\n",
    "                    tpm[i, j] = distribution_training.loc[(distribution_training['action'] == 'store') & (distribution_training['color'] == 'red'), 'count'].item()\n",
    "                elif next_action == 'store_white':\n",
    "                    tpm[i, j] = distribution_training.loc[(distribution_training['action'] == 'store') & (distribution_training['color'] == 'white'), 'count'].item()\n",
    "                elif next_action == 'store_blue':\n",
    "                    tpm[i, j] = distribution_training.loc[(distribution_training['action'] == 'store') & (distribution_training['color'] == 'blue'), 'count'].item()\n",
    "                elif next_action == 'pick_up_red':\n",
    "                    tpm[i, j] = distribution_training.loc[(distribution_training['action'] == 'restore') & (distribution_training['color'] == 'red'), 'count'].item()\n",
    "                elif next_action == 'pick_up_white':\n",
    "                    tpm[i, j] = distribution_training.loc[(distribution_training['action'] == 'restore') & (distribution_training['color'] == 'white'), 'count'].item()\n",
    "                else:\n",
    "                    tpm[i, j] = distribution_training.loc[(distribution_training['action'] == 'restore') & (distribution_training['color'] == 'blue'), 'count'].item()\n",
    "        \n",
    "    tpm_with_good_distribution = transition_probability_matrix_correction(tpm)\n",
    "    all_tpm.append(tpm_with_good_distribution)\n",
    "\n",
    "print(len(all_tpm))\n",
    "all_tpm[:1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reward\n",
    "\n",
    "A Reward Rt is a scalar feedback signal that indicates how well the agent is doing at time step t. The agent's job is to maximize the expected sum of rewards. \n",
    "\n",
    "A Reward is a real-valued reward function. R(s) indicates the reward for simply being in the state S. \n",
    "\n",
    "R(S,a) indicates the reward for being in a state S and taking an action ‘a’. \n",
    "\n",
    "R(S,a,S’) indicates the reward for being in a state S, taking an action ‘a’ and ending up in a state S’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3. 4.]\n",
      " [1. 2. 3. 4.]\n",
      " [1. 2. 3. 4.]\n",
      " ...\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "rewards_matrix = np.zeros((len(all_states), len(slot_positions)))\n",
    "for position in slot_positions:\n",
    "    for i, current_state in enumerate(all_states, start=0):\n",
    "        if current_state[position] == 'empty':\n",
    "            rewards_matrix[i, position] = position + 1\n",
    "\n",
    "print(rewards_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Policy \n",
    "\n",
    "A Policy is a solution to the Markov Decision Process. A policy is a mapping from S to a. It indicates the action ‘a’ to be taken while in state S.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolicyIteration:\n",
      "(3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "(5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418585, 4.5179682614185985, 4.517968261418586, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972525, 3.605756001297253, 3.6057560012972534, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972525, 3.605756001297253, 3.6057560012972534, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972525, 3.605756001297253, 3.6057560012972534, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418606, 4.517968261418597, 4.51796826141858, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.672197320852085, 2.672197320852085, 2.672197320852085, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.672197320852085, 2.672197320852085, 2.672197320852085, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.672197320852085, 2.672197320852085, 2.672197320852085, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.5179682614186145, 4.5179682614185985, 4.517968261418595, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.672197320852085, 2.672197320852085, 2.672197320852085, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.672197320852085, 2.672197320852085, 2.672197320852085, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.672197320852084, 2.672197320852085, 2.672197320852085, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418602, 4.517968261418596, 4.517968261418611, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.672197320852084, 2.672197320852085, 2.672197320852085, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.672197320852084, 2.672197320852085, 2.672197320852085, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.672197320852084, 2.672197320852085, 2.672197320852085, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418588, 4.517968261418594, 4.517968261418605, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297248, 3.605756001297252, 3.6057560012972547, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972485, 3.6057560012972507, 3.6057560012972534, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972507, 3.6057560012972454, 3.605756001297257, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418598, 4.517968261418592, 4.517968261418603, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418599, 4.517968261418601, 4.517968261418602, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418597, 4.5179682614186, 4.5179682614186, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418594, 4.517968261418608, 4.517968261418592, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297251, 3.60575600129725, 3.6057560012972507, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972516, 3.6057560012972503, 3.605756001297258, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972543, 3.605756001297253, 3.6057560012972534, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418608, 4.517968261418607, 4.517968261418597, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418597, 4.5179682614186, 4.517968261418594, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418603, 4.517968261418599, 4.517968261418593, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418606, 4.517968261418599, 4.517968261418598, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972534, 3.6057560012972565, 3.6057560012972547, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972516, 3.6057560012972525, 3.6057560012972543, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297251, 3.605756001297251, 3.6057560012972543, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418607, 4.517968261418603, 4.517968261418598, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.5179682614185985, 4.517968261418599, 4.517968261418595, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418612, 4.517968261418603, 4.517968261418601, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 1.4285714285714286, 1.4285714285714286, 1.4285714285714286, 1.7223715286792602, 1.7223715286792602, 1.7223715286792602, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418597, 4.5179682614186065, 4.517968261418602, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297252, 3.605756001297257, 3.605756001297255, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972534, 3.605756001297254, 3.6057560012972534, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297253, 3.6057560012972534, 3.6057560012972516, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418598, 4.517968261418604, 4.517968261418601, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.6721973208520886, 2.672197320852088, 2.6721973208520877, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.67219732085209, 2.6721973208520855, 2.6721973208520833, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.6721973208520904, 2.6721973208520873, 2.672197320852085, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.5179682614186, 4.517968261418601, 4.517968261418599, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.6721973208520873, 2.6721973208520877, 2.6721973208520886, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.6721973208520877, 2.672197320852089, 2.672197320852085, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.672197320852088, 2.6721973208520873, 2.6721973208520846, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418599, 4.5179682614185985, 4.517968261418598, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.672197320852089, 2.6721973208520895, 2.672197320852086, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.672197320852089, 2.6721973208520886, 2.672197320852086, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.6721973208520873, 2.672197320852087, 2.672197320852083, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418604, 4.517968261418605, 4.517968261418591, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297257, 3.6057560012972534, 3.605756001297254, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297255, 3.605756001297258, 3.605756001297256, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972525, 3.6057560012972543, 3.605756001297254, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418599, 4.517968261418599, 4.517968261418598, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418603, 4.517968261418602, 4.517968261418599, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418599, 4.517968261418599, 4.517968261418602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418603, 4.517968261418604, 4.5179682614185985, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297255, 3.6057560012972556, 3.6057560012972543, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972547, 3.6057560012972547, 3.605756001297252, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297253, 3.6057560012972574, 3.6057560012972534, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.5179682614185985, 4.5179682614186, 4.517968261418603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418593, 4.517968261418601, 4.517968261418599, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.5179682614186, 4.517968261418602, 4.5179682614186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418595, 4.517968261418603, 4.517968261418601, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972596, 3.6057560012972525, 3.6057560012972556, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297255, 3.6057560012972534, 3.6057560012972525, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297254, 3.605756001297254, 3.605756001297251, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418604, 4.5179682614186065, 4.517968261418595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418605, 4.517968261418608, 4.517968261418606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418606, 4.517968261418605, 4.517968261418603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418599, 4.517968261418601, 4.517968261418598, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297253, 3.605756001297254, 3.6057560012972534, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972543, 3.605756001297257, 3.6057560012972547, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972556, 3.605756001297259, 3.6057560012972547, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.5179682614186, 4.517968261418603, 4.517968261418598, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.672197320852087, 2.6721973208520877, 2.6721973208520846, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.672197320852088, 2.672197320852089, 2.6721973208520877, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.672197320852089, 2.6721973208520873, 2.6721973208520873, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418596, 4.517968261418603, 4.5179682614186, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.6721973208520877, 2.672197320852087, 2.6721973208520864, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.6721973208520904, 2.6721973208520904, 2.672197320852089, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.672197320852089, 2.672197320852089, 2.67219732085209, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.5179682614186, 4.517968261418606, 4.5179682614185985, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.6721973208520873, 2.672197320852091, 2.672197320852087, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.6721973208520904, 2.6721973208520886, 2.6721973208520895, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.6721973208520886, 2.6721973208520864, 2.672197320852086, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418607, 4.517968261418608, 4.517968261418607, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297252, 3.605756001297254, 3.605756001297252, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972556, 3.605756001297255, 3.6057560012972543, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972507, 3.6057560012972556, 3.605756001297253, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418601, 4.517968261418609, 4.517968261418603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418601, 4.517968261418608, 4.517968261418602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418605, 4.517968261418613, 4.517968261418607, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418608, 4.517968261418606, 4.5179682614186065, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297251, 3.6057560012972565, 3.6057560012972525, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972534, 3.605756001297255, 3.605756001297253, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297253, 3.6057560012972547, 3.605756001297252, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.5179682614185985, 4.517968261418608, 4.517968261418602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418602, 4.517968261418607, 4.51796826141861, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418601, 4.517968261418614, 4.517968261418605, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418601, 4.5179682614186065, 4.5179682614186065, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297253, 3.6057560012972556, 3.6057560012972543, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297253, 3.605756001297256, 3.6057560012972525, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972534, 3.605756001297255, 3.6057560012972543, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418598, 4.517968261418606, 4.5179682614186065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418602, 4.5179682614186065, 4.517968261418603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418603, 4.517968261418608, 4.517968261418607, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418605, 4.517968261418612, 4.5179682614186065, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297254, 3.6057560012972543, 3.605756001297252, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297252, 3.605756001297254, 3.6057560012972525, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972525, 3.6057560012972547, 3.6057560012972543, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.5179682614186065, 4.51796826141861, 4.5179682614186065, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.6721973208520864, 2.6721973208520904, 2.6721973208520864, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.672197320852089, 2.6721973208520895, 2.672197320852089, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.672197320852089, 2.672197320852089, 2.672197320852087, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418602, 4.517968261418612, 4.5179682614186065, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.672197320852089, 2.6721973208520904, 2.6721973208520877, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.6721973208520895, 2.6721973208520877, 2.67219732085209, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.67219732085209, 2.6721973208520904, 2.672197320852089, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418601, 4.517968261418604, 4.517968261418608, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.6721973208520895, 2.6721973208520877, 2.672197320852088, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.672197320852088, 2.6721973208520886, 2.672197320852088, 2.857142857142857, 2.857142857142857, 2.857142857142857, 2.672197320852091, 2.672197320852088, 2.672197320852087, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418605, 4.517968261418607, 4.517968261418609, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972507, 3.6057560012972534, 3.605756001297253, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972516, 3.6057560012972556, 3.605756001297253, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297251, 3.605756001297256, 3.6057560012972543, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.5179682614186, 4.517968261418611, 4.517968261418609, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418602, 4.51796826141861, 4.51796826141861, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418602, 4.517968261418612, 4.517968261418609, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418604, 4.517968261418609, 4.5179682614186065, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297254, 3.6057560012972543, 3.605756001297253, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972534, 3.605756001297255, 3.605756001297255, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972525, 3.6057560012972556, 3.605756001297253, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418601, 4.517968261418612, 4.517968261418613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418603, 4.517968261418612, 4.51796826141861, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418604, 4.517968261418613, 4.51796826141861, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418606, 4.517968261418609, 4.517968261418608, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.6057560012972543, 3.605756001297258, 3.605756001297253, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297254, 3.6057560012972556, 3.6057560012972534, 4.285714285714286, 4.285714285714286, 4.285714285714286, 3.605756001297254, 3.605756001297256, 3.605756001297253, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418605, 4.517968261418613, 4.517968261418609, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418603, 4.517968261418612, 4.51796826141861, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.714285714285714, 5.714285714285714, 5.714285714285714, 4.517968261418604, 4.517968261418612, 4.517968261418611, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
      "1\n",
      "ValueIteration:\n",
      "(3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "(5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 1.4251, 1.4251, 1.4251, 1.7181132654272062, 1.7181132654272062, 1.7181132654272062, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 2.8502, 2.8502, 2.8502, 2.6681671083584444, 2.6681671083584444, 2.6681671083584444, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 4.2753, 4.2753, 4.2753, 3.602023352203741, 3.602023352203741, 3.602023352203741, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7004, 5.7004, 5.7004, 4.514621395663232, 4.514621395663232, 4.514621395663232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "mdpResultPolicy = mdptoolbox.mdp.PolicyIteration(all_tpm, rewards_matrix, 0.3, max_iter=100)\n",
    "mdpResultValue = mdptoolbox.mdp.ValueIteration(all_tpm, rewards_matrix, 0.3, max_iter=100)\n",
    "\n",
    "\"\"\"-------- HERE ARE THE SOLUTIONS ----------------\"\"\"\n",
    "mdpResultPolicy.run()\n",
    "mdpResultValue.run()\n",
    "\n",
    "print('PolicyIteration:')\n",
    "print(mdpResultPolicy.policy)\n",
    "print(mdpResultPolicy.V)\n",
    "print(mdpResultPolicy.iter)\n",
    "\n",
    "print('ValueIteration:')\n",
    "print(mdpResultValue.policy)\n",
    "print(mdpResultValue.V)\n",
    "print(mdpResultValue.iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Testing\n",
    "\n",
    "We will use the solution we have just found (policy) through the training of our model and use it on the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_new_warehouse(warehouse, agent_position, action, color):\n",
    "    if action == 'store' and warehouse[agent_position] == 'empty':\n",
    "        warehouse[agent_position] = color\n",
    "    elif action == 'restore' and warehouse[agent_position] != 'empty':\n",
    "        warehouse[agent_position] = 'empty'\n",
    "    return warehouse\n",
    "\n",
    "\n",
    "def state_number(warehouse):\n",
    "    for index, current_state in enumerate(all_states, start=0):\n",
    "        if current_state == tuple(warehouse):\n",
    "            return index\n",
    "    return 'failed'\n",
    "\n",
    "def current_warehouse_state(warehouse, action, color):\n",
    "    if action == 'store':\n",
    "        if color == 'red':\n",
    "            action='store_red'\n",
    "        if color == 'white':\n",
    "            action='store_white'\n",
    "        if color == 'blue':\n",
    "            action='store_blue'\n",
    "    elif action == 'restore':\n",
    "        if color == 'red':\n",
    "            action='pick_up_red'\n",
    "        if color == 'white':\n",
    "            action='pick_up_white'\n",
    "        if color == 'blue':\n",
    "            action='pick_up_blue'\n",
    "    if len(warehouse) == len(slot_positions):\n",
    "        warehouse.append(action)\n",
    "    elif len(warehouse) == len(slot_positions) + 1:\n",
    "        warehouse[len(slot_positions)] = action\n",
    "    return warehouse\n",
    "        \n",
    "def test_algorithm(policy: tuple):\n",
    "    warehouse = ['empty']*len(slot_positions)\n",
    "\n",
    "    slot_to_move = 0\n",
    "    warehouse_states = []\n",
    "    \n",
    "    for i, row in testing_data_set.iterrows():\n",
    "        action_warehouse = current_warehouse_state(warehouse, row.action, row.color)\n",
    "        \n",
    "        state = state_number(action_warehouse)\n",
    "        \n",
    "        if state != 'failed':\n",
    "            warehouse_position = policy[state]\n",
    "            slot_to_move += travel_costs[warehouse_position] * 2\n",
    "            warehouse = determine_new_warehouse(warehouse, warehouse_position, row.action, row.color)\n",
    "            warehouse_tuple = tuple(warehouse)\n",
    "            warehouse_states.append(warehouse_tuple)\n",
    "        else:\n",
    "            print(action_warehouse, state)\n",
    "            return 'failed'\n",
    "    result = [slot_to_move, warehouse_states]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueIteration Robot traveled:  144\n",
      "PolicyIteration Robot traveled:  144\n",
      "[('empty', 'empty', 'empty', 'red', 'store_red'), ('empty', 'empty', 'white', 'red', 'store_white'), ('empty', 'empty', 'white', 'red', 'pick_up_white'), ('empty', 'red', 'white', 'red', 'store_red'), ('blue', 'red', 'white', 'red', 'store_blue'), ('blue', 'red', 'white', 'red', 'store_red'), ('empty', 'red', 'white', 'red', 'pick_up_red'), ('empty', 'red', 'white', 'red', 'pick_up_red'), ('empty', 'red', 'white', 'red', 'pick_up_red'), ('red', 'red', 'white', 'red', 'store_red'), ('empty', 'red', 'white', 'red', 'pick_up_blue'), ('empty', 'red', 'white', 'red', 'pick_up_red'), ('blue', 'red', 'white', 'red', 'store_blue'), ('empty', 'red', 'white', 'red', 'pick_up_blue'), ('red', 'red', 'white', 'red', 'store_red'), ('red', 'red', 'white', 'red', 'store_red'), ('red', 'red', 'white', 'red', 'store_blue'), ('empty', 'red', 'white', 'red', 'pick_up_blue'), ('empty', 'red', 'white', 'red', 'pick_up_red'), ('red', 'red', 'white', 'red', 'store_red'), ('red', 'red', 'white', 'red', 'store_blue'), ('empty', 'red', 'white', 'red', 'pick_up_blue'), ('empty', 'red', 'white', 'red', 'pick_up_red'), ('blue', 'red', 'white', 'red', 'store_blue'), ('blue', 'red', 'white', 'red', 'store_white'), ('blue', 'red', 'white', 'red', 'store_red'), ('empty', 'red', 'white', 'red', 'pick_up_red'), ('empty', 'red', 'white', 'red', 'pick_up_red'), ('empty', 'red', 'white', 'red', 'pick_up_blue'), ('red', 'red', 'white', 'red', 'store_red'), ('empty', 'red', 'white', 'red', 'pick_up_red'), ('white', 'red', 'white', 'red', 'store_white'), ('white', 'red', 'white', 'red', 'store_red'), ('white', 'red', 'white', 'red', 'store_red'), ('empty', 'red', 'white', 'red', 'pick_up_red'), ('red', 'red', 'white', 'red', 'store_red'), ('empty', 'red', 'white', 'red', 'pick_up_red'), ('empty', 'red', 'white', 'red', 'pick_up_red'), ('empty', 'red', 'white', 'red', 'pick_up_white'), ('empty', 'red', 'white', 'red', 'pick_up_white'), ('blue', 'red', 'white', 'red', 'store_blue'), ('blue', 'red', 'white', 'red', 'store_white'), ('blue', 'red', 'white', 'red', 'store_blue'), ('empty', 'red', 'white', 'red', 'pick_up_white'), ('empty', 'red', 'white', 'red', 'pick_up_blue'), ('empty', 'red', 'white', 'red', 'pick_up_blue'), ('white', 'red', 'white', 'red', 'store_white'), ('white', 'red', 'white', 'red', 'store_red'), ('white', 'red', 'white', 'red', 'store_red'), ('white', 'red', 'white', 'red', 'store_red'), ('empty', 'red', 'white', 'red', 'pick_up_red'), ('empty', 'red', 'white', 'red', 'pick_up_white'), ('empty', 'red', 'white', 'red', 'pick_up_red'), ('empty', 'red', 'white', 'red', 'pick_up_red'), ('white', 'red', 'white', 'red', 'store_white'), ('empty', 'red', 'white', 'red', 'pick_up_white'), ('white', 'red', 'white', 'red', 'store_white'), ('white', 'red', 'white', 'red', 'store_white'), ('white', 'red', 'white', 'red', 'store_blue'), ('white', 'red', 'white', 'red', 'store_white'), ('empty', 'red', 'white', 'red', 'pick_up_blue'), ('empty', 'red', 'white', 'red', 'pick_up_white'), ('empty', 'red', 'white', 'red', 'pick_up_white'), ('white', 'red', 'white', 'red', 'store_white'), ('white', 'red', 'white', 'red', 'store_red')]\n"
     ]
    }
   ],
   "source": [
    "traveled_fields_mdpResultPolicy = test_algorithm(mdpResultPolicy.policy)\n",
    "traveled_fields_mdpResultValue = test_algorithm(mdpResultValue.policy)\n",
    "\n",
    "print(\"ValueIteration Robot traveled: \", traveled_fields_mdpResultValue[0])\n",
    "value_iter_states = traveled_fields_mdpResultValue[1]\n",
    "\n",
    "print(\"PolicyIteration Robot traveled: \", traveled_fields_mdpResultPolicy[0])\n",
    "policy_iter_states = traveled_fields_mdpResultPolicy[1]\n",
    "print(policy_iter_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Evaluation with Greedy algorithm\n",
    "\n",
    "In order to be able to compare and evaluate our model, we also want to implement a Greedy algorithm and use it also on our test data to better assess the quality of our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_in_next_empty(warehouse, color, travel_costs):\n",
    "    for index, pos in enumerate(warehouse, start=0):\n",
    "        if pos == 'empty':\n",
    "            warehouse[index] = color\n",
    "            result = [travel_costs[index] * 2, warehouse]\n",
    "            return result\n",
    "        \n",
    "    return False\n",
    "\n",
    "def correction_first_slot(warehouse, color, travel_costs):\n",
    "    for index, pos in enumerate(warehouse, start=0):\n",
    "        if pos == color:\n",
    "            warehouse[index] = 'empty'\n",
    "            result = [travel_costs[index]*2, warehouse]\n",
    "            return result\n",
    "        \n",
    "    return False\n",
    "\n",
    "def greedy_distance(travel_costs):\n",
    "    warehouse = ['empty'] * len(slot_positions)\n",
    "    \n",
    "    distance_traveled = 0\n",
    "    \n",
    "    warehouse_states = []\n",
    "    \n",
    "    for index, row in testing_data_set.iterrows():\n",
    "        warehouse_state = ''\n",
    "        if row.action == 'store':\n",
    "            warehouse_state = store_in_next_empty(warehouse, row.color, travel_costs)\n",
    "            warehouse_tuple_store = tuple(warehouse_state[1])\n",
    "            warehouse_states.append(warehouse_tuple_store)\n",
    "            distance_traveled += warehouse_state[0]\n",
    "        elif row.action == 'restore':\n",
    "            warehouse_state = correction_first_slot(warehouse, row.color, travel_costs)\n",
    "            warehouse_tuple_restore = tuple(warehouse_state[1])\n",
    "            warehouse_states.append(warehouse_tuple_restore)\n",
    "            distance_traveled += warehouse_state[0]\n",
    "    \n",
    "    result = [distance_traveled, warehouse_states]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy Robot traveled:  274\n",
      "[('red', 'empty', 'empty', 'empty'), ('red', 'white', 'empty', 'empty'), ('red', 'empty', 'empty', 'empty'), ('red', 'red', 'empty', 'empty'), ('red', 'red', 'blue', 'empty'), ('red', 'red', 'blue', 'red'), ('empty', 'red', 'blue', 'red'), ('empty', 'empty', 'blue', 'red'), ('empty', 'empty', 'blue', 'empty'), ('red', 'empty', 'blue', 'empty'), ('red', 'empty', 'empty', 'empty'), ('empty', 'empty', 'empty', 'empty'), ('blue', 'empty', 'empty', 'empty'), ('empty', 'empty', 'empty', 'empty'), ('red', 'empty', 'empty', 'empty'), ('red', 'red', 'empty', 'empty'), ('red', 'red', 'blue', 'empty'), ('red', 'red', 'empty', 'empty'), ('empty', 'red', 'empty', 'empty'), ('red', 'red', 'empty', 'empty'), ('red', 'red', 'blue', 'empty'), ('red', 'red', 'empty', 'empty'), ('empty', 'red', 'empty', 'empty'), ('blue', 'red', 'empty', 'empty'), ('blue', 'red', 'white', 'empty'), ('blue', 'red', 'white', 'red'), ('blue', 'empty', 'white', 'red'), ('blue', 'empty', 'white', 'empty'), ('empty', 'empty', 'white', 'empty'), ('red', 'empty', 'white', 'empty'), ('empty', 'empty', 'white', 'empty'), ('white', 'empty', 'white', 'empty'), ('white', 'red', 'white', 'empty'), ('white', 'red', 'white', 'red'), ('white', 'empty', 'white', 'red'), ('white', 'red', 'white', 'red'), ('white', 'empty', 'white', 'red'), ('white', 'empty', 'white', 'empty'), ('empty', 'empty', 'white', 'empty'), ('empty', 'empty', 'empty', 'empty'), ('blue', 'empty', 'empty', 'empty'), ('blue', 'white', 'empty', 'empty'), ('blue', 'white', 'blue', 'empty'), ('blue', 'empty', 'blue', 'empty'), ('empty', 'empty', 'blue', 'empty'), ('empty', 'empty', 'empty', 'empty'), ('white', 'empty', 'empty', 'empty'), ('white', 'red', 'empty', 'empty'), ('white', 'red', 'red', 'empty'), ('white', 'red', 'red', 'red'), ('white', 'empty', 'red', 'red'), ('empty', 'empty', 'red', 'red'), ('empty', 'empty', 'empty', 'red'), ('empty', 'empty', 'empty', 'empty'), ('white', 'empty', 'empty', 'empty'), ('empty', 'empty', 'empty', 'empty'), ('white', 'empty', 'empty', 'empty'), ('white', 'white', 'empty', 'empty'), ('white', 'white', 'blue', 'empty'), ('white', 'white', 'blue', 'white'), ('white', 'white', 'empty', 'white'), ('empty', 'white', 'empty', 'white'), ('empty', 'empty', 'empty', 'white'), ('white', 'empty', 'empty', 'white'), ('white', 'red', 'empty', 'white')]\n"
     ]
    }
   ],
   "source": [
    "traveled_fields_greedy = greedy_distance(travel_costs)\n",
    "\n",
    "print(\"Greedy Robot traveled: \", traveled_fields_greedy[0])\n",
    "\n",
    "greedy_states = traveled_fields_greedy[1]\n",
    "print(greedy_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the sources used for the realization of this article...\n",
    "\n",
    "References :\n",
    "\n",
    "<a href=\"https://towardsdatascience.com/reinforcement-learning-demystified-36c39c11ec14\">Reinforcement Learning Demystified</a>\n",
    "\n",
    "<a href=\"https://towardsdatascience.com/reinforcement-learning-an-introduction-to-the-concepts-applications-and-code-ced6fbfd882d\">Reinforcement Learning: An Introduction to the Concepts, Applications and Code</a>\n",
    "\n",
    "<a href=\"https://medium.com/coinmonks/implement-reinforcement-learning-using-markov-decision-process-tutorial-272012fdae51\">Implement Reinforcement learning using Markov Decision Process</a>\n",
    "\n",
    "<a href=\"http://www.cs.cmu.edu/~10601b/slides/MDP_RL.pdf\">Markov Decision Process and Reinforcement Learning</a>\n",
    "\n",
    "<a href=\"https://hub.packtpub.com/reinforcement-learning-mdp-markov-decision-process-tutorial/\">Implement Reinforcement learning using Markov Decision Process [Tutorial]</a>\n",
    "\n",
    "<a href=\"https://www.geeksforgeeks.org/markov-decision-process/\">Markov Decision Process</a>\n",
    "\n",
    "<a href=\"http://incompleteideas.net/book/bookdraft2017nov5.pdf\">SB11 - Sutton Barto - Book - Reinforcement Learning.pdf</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
